{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INTERSPEECH_ZTM05.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarolChlasta/ADReSS-Challenge2020/blob/master/Experiments/AD-Classification-Task/10/AudioNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWxcjd8ppT4",
        "colab_type": "text"
      },
      "source": [
        "# Requirements Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe7h_wnIVNbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiYjL0Hvpopj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch torchvision fastai==0.7.0 PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpZNW70Mp122",
        "colab_type": "text"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-gbdc6Np3aH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pathlib import Path\n",
        "import os\n",
        "from collections import Counter\n",
        "import wave\n",
        "import struct\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from scipy.io import wavfile\n",
        "from scipy.signal import decimate\n",
        "from scipy import signal\n",
        "from scipy import fft, arange\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from pylab import *\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from fastai.imports import *\n",
        "from fastai.transforms import *\n",
        "from fastai.conv_learner import *\n",
        "from fastai.model import *\n",
        "from fastai.dataset import *\n",
        "from fastai.sgdr import *\n",
        "from fastai.plots import *\n",
        "from fastai.io import *\n",
        "from fastai.column_data import *\n",
        "import sys\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "from functools import reduce   \n",
        "mpl.style.use('seaborn-ticks')\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "np.set_printoptions(precision=2, suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otdKP3clA-9w",
        "colab_type": "text"
      },
      "source": [
        "# Terminal Colors Class (Aesthetics)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju7CfJu_BB4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZeMT8mEqQTw",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive Downloader Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tBkKfH3qP0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Downloader:\n",
        "    def __init__(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "    def __call__(self, dataset_file_name, dataset_file_id):\n",
        "        downloaded = self.drive.CreateFile({'id': dataset_file_id})\n",
        "        downloaded.FetchContent()\n",
        "        with open(dataset_file_name,'wb') as f:\n",
        "            f.write(downloaded.content.read())\n",
        "        print(f'{bcolors.HEADER}Saved {dataset_file_name}{bcolors.ENDC}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSM6HsK2B-rP",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll-Mp_6WsavK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scan_dataset_folders(dataset_paths):\n",
        "    x_filenames = []\n",
        "    y_classes = []\n",
        "    print(f\"{bcolors.HEADER}Class Counts: {bcolors.ENDC}\")\n",
        "    for dataset_path in dataset_paths:\n",
        "        class_paths = sorted([x for x in list(dataset_path.iterdir()) if x.name[0] != '.'])\n",
        "        for class_path in class_paths:\n",
        "            samples_fn = sorted(list(class_path.iterdir()))\n",
        "            print(f\"\\t{bcolors.HEADER}{class_path.name}: {len(samples_fn)}{bcolors.ENDC}\")\n",
        "            for sample_fn in samples_fn:\n",
        "                x_filenames.append(sample_fn)\n",
        "                y_classes.append(class_path.name)\n",
        "    return x_filenames, y_classes\n",
        "\n",
        "def load_wav_file(path, sample_rate):\n",
        "    framerate, samples = wavfile.read(str(path))\n",
        "    assert framerate == sample_rate\n",
        "    duration = len(samples)/framerate\n",
        "    return samples, framerate, duration\n",
        "\n",
        "def repeat_to_length(arr, length):\n",
        "    \"\"\"Repeats the numpy 1D array to given length, and makes datatype float\"\"\"\n",
        "    result = np.empty((length, ), dtype = 'float32')\n",
        "    l = len(arr)\n",
        "    pos = 0\n",
        "    while pos + l <= length:\n",
        "        result[pos:pos+l] = arr\n",
        "        pos += l\n",
        "    if pos < length:\n",
        "        result[pos:length] = arr[:length-pos]\n",
        "    return result\n",
        "\n",
        "def downsample(samples, framerate, dfs=[8,8,4]):\n",
        "    '''dfs - downsampling factors'''\n",
        "    # TODO: make it work for multiple samples\n",
        "    s=np.array(samples)    \n",
        "    s=s[np.newaxis,:]\n",
        "\n",
        "    for df in dfs:\n",
        "        s = signal.decimate(s, df, axis=1, zero_phase=True)\n",
        "    s = s[0,:]\n",
        "    \n",
        "    #Scale each observation to unit variance, it should already have mean close to zero.\n",
        "    s = s / np.std(s)\n",
        "\n",
        "    return s\n",
        "\n",
        "def downsampled_framerate(framerate, dfs=[8,8,4]):\n",
        "    product = reduce((lambda x, y: x * y), dfs)\n",
        "    framerate2=framerate/product\n",
        "    return framerate2\n",
        "\n",
        "def times_array(s, framerate2):\n",
        "    t2 = [float(i)/framerate2 for i in range(len(s))]\n",
        "    return t2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEOYdE0OseNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetSample:\n",
        "    # source data\n",
        "    fn_path = None\n",
        "    framerate = None \n",
        "    samples = None \n",
        "    duration = None\n",
        "    y_class = None\n",
        "    \n",
        "    # processed data\n",
        "    # samples_repeated = None\n",
        "    samples_9s = None\n",
        "    samples_downsampled = None\n",
        "    downsampled_framerate = None\n",
        "    y = None\n",
        "    \n",
        "    def __repr__(self):\n",
        "            \"\"\"\"\"\"\n",
        "            return \"<DatasetSample: %s>\" % self.__dict__\n",
        "    \n",
        "    def __init__(self, fn_path, framerate, samples, duration, y_class = None):\n",
        "        self.fn_path = fn_path\n",
        "        self.framerate = framerate\n",
        "        self.samples = samples\n",
        "        self.duration = duration\n",
        "        self.y_class = y_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-v_XDP3sfol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset_sample_from_file(fn_path, sample_rate):\n",
        "    samples, framerate, duration = load_wav_file(fn_path, sample_rate)\n",
        "    ds_sample = DatasetSample(fn_path, framerate, samples, duration)    \n",
        "    return ds_sample\n",
        "\n",
        "def load_all_dataset_samples(PATH, sample_rate, min_duration=None):\n",
        "    x_filenames, y_classes = scan_dataset_folders(PATH)    \n",
        "    all_ds_samples = [dataset_sample_from_file(fn_path, sample_rate) for fn_path in x_filenames]\n",
        "    \n",
        "    for ds_sample, y_class in zip(all_ds_samples, y_classes):\n",
        "        ds_sample.y_class = y_class\n",
        "    \n",
        "    if min_duration is not None:\n",
        "        ds_samples = [ds for ds in all_ds_samples if ds.duration>=min_duration]\n",
        "    else:\n",
        "        ds_samples = all_ds_samples\n",
        "    \n",
        "    return ds_samples\n",
        "\n",
        "def process_dataset_sample(CLASS2IDX, ds_sample, expected_length, downsampling_factors):\n",
        "    ds_sample.samples_9s = ds_sample.samples[:expected_length]\n",
        "    ds_sample.duration = len(ds_sample.samples_9s)/ds_sample.framerate\n",
        "    samples_repeated = repeat_to_length(ds_sample.samples_9s, expected_length)\n",
        "    samples_downsampled = downsample(samples_repeated, ds_sample.framerate, downsampling_factors)    \n",
        "    ds_sample.samples_downsampled = samples_downsampled\n",
        "    ds_sample.framerate_downsampled = downsampled_framerate(ds_sample.framerate, downsampling_factors)    \n",
        "    ds_sample.y = CLASS2IDX[ds_sample.y_class] if ds_sample.y_class is not None else None\n",
        "    return ds_sample\n",
        "\n",
        "def get_expected_length(ds_samples):\n",
        "    largest = 0\n",
        "    for ds_sample in tqdm(ds_samples, desc=f\"{bcolors.HEADER}getting expected length{bcolors.ENDC}\"):\n",
        "        full_length = len(ds_sample.samples)\n",
        "        largest = max(largest, full_length)\n",
        "    print(f\"{bcolors.OKBLUE}expected length: {largest}{bcolors.ENDC}\")\n",
        "    return largest\n",
        "\n",
        "def process_dataset_samples(CLASS2IDX, ds_samples, expected_length, downsampling_factors):\n",
        "    for ds in tqdm(ds_samples, desc=f\"{bcolors.HEADER}processing dataset samples{bcolors.ENDC}\"):\n",
        "        ds = process_dataset_sample(CLASS2IDX, ds, expected_length, downsampling_factors)\n",
        "    return ds_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH4QT7iYOgov",
        "colab_type": "text"
      },
      "source": [
        "# Plotting Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx3jHgQisi2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotSpectrogram(s, framerate2):\n",
        "    \"\"\"\n",
        "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html\n",
        "    \"\"\"    \n",
        "    f, t, Sxx = signal.spectrogram(s, framerate2, nperseg=64, noverlap=32)\n",
        "    plt.pcolormesh(t, f, Sxx)\n",
        "    plt.ylabel('Frequency [Hz]')\n",
        "    plt.xlabel('Time [sec]')\n",
        "\n",
        "def plotSpectrum(y,Fs):\n",
        "    \"\"\"\n",
        "    Plots a Single-Sided Amplitude Spectrum of y(t)\n",
        "    https://glowingpython.blogspot.com/2011/08/how-to-plot-frequency-spectrum-with.html\n",
        "    \"\"\"\n",
        "    n = len(y) # length of the signal\n",
        "    k = arange(n)\n",
        "    T = n/Fs\n",
        "    frq = k/T # two sides frequency range\n",
        "    frq = frq[range(n//2)] # one side frequency range\n",
        "\n",
        "    Y = fft(y)/n # fft computing and normalization\n",
        "    Y = Y[range(n//2)]\n",
        "\n",
        "    plt.plot(frq,abs(Y),'r') # plotting the spectrum\n",
        "    plt.xlabel('Freq (Hz)')\n",
        "    plt.ylabel('|Y(freq)|')\n",
        "\n",
        "def plotWaveform(s, t2):\n",
        "    plt.plot(t2, s)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Amplitude')\n",
        "\n",
        "def plotWaveformSpectrogramAndSpectrum(s, framerate2, t2, title=\"\"):\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(3,1,1)\n",
        "    plt.title(title)\n",
        "    plotWaveform(s, t2)\n",
        "    plt.subplot(3,1,2)\n",
        "    plotSpectrogram(s, framerate2)\n",
        "    plt.subplot(3,1,3)\n",
        "    plotSpectrum(s, framerate2)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-yZhgbaCsuO",
        "colab_type": "text"
      },
      "source": [
        "# Custom Convolutional Neural Network for Heart Beat Sound Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH4ZBQLksrHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HeartbeatSoundsConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes=2):\n",
        "        super(HeartbeatSoundsConvNet, self).__init__()\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.b1 = nn.Sequential(*[\n",
        "            # Conv1D(... kernel_regularizer = l2(0.025))\n",
        "            nn.Conv1d(in_channels=1, out_channels=4, kernel_size=9),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=9, stride=4),\n",
        "            nn.BatchNorm1d(num_features=4),\n",
        "            nn.Dropout(p=0.2)\n",
        "            # nn.Dropout(p=0.025)\n",
        "        ])\n",
        "\n",
        "        self.b2 = nn.Sequential(*[\n",
        "            # Conv1D(... kernel_regularizer = l2(0.05))\n",
        "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=9, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=9, stride=4, padding=4),\n",
        "            nn.BatchNorm1d(num_features=4),\n",
        "            nn.Dropout(p=0.2)\n",
        "            # nn.Dropout(p=0.05)\n",
        "        ])\n",
        "\n",
        "        self.b3 = nn.Sequential(*[\n",
        "            # Conv1D(... kernel_regularizer = l2(0.1))\n",
        "            nn.Conv1d(in_channels=4, out_channels=8, kernel_size=9),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=9, stride=4, padding=4),\n",
        "            nn.BatchNorm1d(num_features=8),\n",
        "            nn.Dropout(p=0.1)\n",
        "        ])\n",
        "\n",
        "        self.b4 = nn.Sequential(*[\n",
        "            nn.Conv1d(in_channels=8, out_channels=16, kernel_size=9),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(kernel_size=9, stride=4, padding=4),\n",
        "            nn.BatchNorm1d(num_features=16),\n",
        "            nn.Dropout(p=0.25),\n",
        "        ])\n",
        "\n",
        "        self.b5 = nn.Sequential(*[\n",
        "            nn.Conv1d(in_channels=16, out_channels=64, kernel_size=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(num_features=64),\n",
        "            nn.Dropout(p=0.5),    \n",
        "        ])\n",
        "\n",
        "        self.b6 = nn.Sequential(*[\n",
        "            nn.Conv1d(in_channels=64, out_channels=32, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(num_features=32),\n",
        "            nn.Dropout(p=0.75),\n",
        "        ])\n",
        "\n",
        "        # https://discuss.pytorch.org/t/global-average-pooling-in-pytorch/6721/8\n",
        "        # jdhao: Also you can use adaptive_avg_pool2d 115 to achieve global average pooling, just set the output size to (1, 1),                \n",
        "        self.b7 = nn.AdaptiveAvgPool1d(output_size=1)  # GlobalAvgPool1D()\n",
        "\n",
        "        self.rest_b7 = nn.Sequential(*[\n",
        "            nn.Linear(in_features=32, out_features=n_classes),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        ])\n",
        "\n",
        "    def forward(self, V):\n",
        "        y = self.b1(V)\n",
        "        y = self.b2(y)\n",
        "        y = self.b3(y)\n",
        "        y = self.b4(y)\n",
        "        y = self.b5(y)\n",
        "        y = self.b6(y)\n",
        "        y = self.b7(y).squeeze()\n",
        "        y = self.rest_b7(y)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWTLUKqRstmA",
        "colab_type": "text"
      },
      "source": [
        "# Validation Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fn6XxwZsvZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_ep_vals(ep_vals):\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    epochs = ep_vals.keys()\n",
        "    plt.xticks(np.asarray(list(epochs)))\n",
        "    trn_losses = [item[0] for item in list(ep_vals.values())]\n",
        "    val_losses = [item[1] for item in list(ep_vals.values())]\n",
        "    plt.plot(epochs, trn_losses, c='g', label='train')\n",
        "    plt.plot(epochs, val_losses, c='r', label='validation')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "def plot_ep_val_acc(ep_vals):\n",
        "    plt.ylabel(\"valit acc\")\n",
        "    epochs = ep_vals.keys()\n",
        "    plt.xticks(np.asarray(list(epochs)))\n",
        "    val_accs = [item[2] for item in list(ep_vals.values())]\n",
        "    plt.plot(epochs, val_accs, c='r', label='valid acc')\n",
        "    plt.legend(loc='upper right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwku0vX4sxF3",
        "colab_type": "text"
      },
      "source": [
        "# Prediction Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOQmJmfXszTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_all(model, x_data, n_classes, batch_size, use_cuda):\n",
        "    # outputs class probabilities\n",
        "    n_samples = x_data.shape[0]\n",
        "    n_iters = n_samples//batch_size\n",
        "    xt = x_data[:,np.newaxis, :]\n",
        "    yt = np.zeros((n_samples, n_classes))\n",
        "    for it in range(n_iters):\n",
        "        idx = it*batch_size\n",
        "        x_batch = Variable(torch.from_numpy(xt[idx:idx+batch_size]).float())\n",
        "\n",
        "        if use_cuda:\n",
        "          x_batch = x_batch.cuda()\n",
        "        \n",
        "        y_batch_pred = model(x_batch)\n",
        "        y_batch_pred = np.exp(y_batch_pred.data.cpu().numpy())\n",
        "        yt[idx:idx+batch_size] = y_batch_pred\n",
        "    return yt\n",
        "\n",
        "def predict_one(model, s, use_cuda, n_classes, classes):    \n",
        "    s_test = s[np.newaxis, :1551]\n",
        "    x_data = np.repeat(s_test, 2, axis=0)\n",
        "\n",
        "    yt = predict_all(model, x_data, n_classes=n_classes, batch_size=2, use_cuda=use_cuda)\n",
        "        \n",
        "    y_hat = yt[0,:]\n",
        "    y_pred = np.argmax(y_hat)\n",
        "    return y_hat, y_pred, classes[y_pred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIB3EhItC6IJ",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessed Audio Dataset Loader Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3H4rGzPs14Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WavDataset(Dataset):\n",
        "    def __init__(self, x, y, rotate_samples=True, multi=1): \n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.rotate_samples = rotate_samples\n",
        "        self.multi = multi\n",
        "\n",
        "    @classmethod\n",
        "    def rotate_sample(cls, x_sample):\n",
        "        \"\"\"\n",
        "        Rotates the time series randomly in time\n",
        "        \"\"\"\n",
        "        x_sample = x_sample.copy()    \n",
        "        sz = np.random.randint(x_sample.shape[0])\n",
        "        x_sample = np.roll(x_sample, sz, axis = 0)\n",
        "\n",
        "        return x_sample\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx = idx % len(self.x)\n",
        "        if self.rotate_samples:\n",
        "            x = self.__class__.rotate_sample(self.x[idx])\n",
        "        else:\n",
        "            x = self.x[idx]\n",
        "        return A(x[np.newaxis,:], self.y[idx])\n",
        "    def __len__(self): return len(self.x) * self.multi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgZL7ba1xPbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOLfpwscYXqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_appropriate_lr(model:Learner, lr_diff:int = 15, loss_threshold:float = .05, adjust_value:float = 1, plot:bool = False) -> float:\n",
        "    #Run the Learning Rate Finder\n",
        "    model.lr_find()\n",
        "    \n",
        "    #Get loss values and their corresponding gradients, and get lr values\n",
        "    losses = np.array(model.sched.losses)\n",
        "    assert(lr_diff < len(losses))\n",
        "    loss_grad = np.gradient(losses)\n",
        "    lrs = model.sched.lrs\n",
        "    \n",
        "    #Search for index in gradients where loss is lowest before the loss spike\n",
        "    #Initialize right and left idx using the lr_diff as a spacing unit\n",
        "    #Set the local min lr as -1 to signify if threshold is too low\n",
        "    r_idx = -1\n",
        "    l_idx = r_idx - lr_diff\n",
        "    local_min_lr = lrs[np.argmin(losses)]\n",
        "    while (l_idx >= -len(losses)) and (abs(loss_grad[r_idx] - loss_grad[l_idx]) > loss_threshold):\n",
        "        local_min_lr = lrs[l_idx]\n",
        "        r_idx -= 1\n",
        "        l_idx -= 1\n",
        "\n",
        "    lr_to_use = local_min_lr * adjust_value\n",
        "    \n",
        "    if plot:\n",
        "        # plots the gradients of the losses in respect to the learning rate change\n",
        "        plt.plot(loss_grad)\n",
        "        plt.plot(len(losses)+l_idx, loss_grad[l_idx],markersize=10,marker='o',color='red')\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.xlabel(\"Index of LRs\")\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(np.log10(lrs), losses)\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.xlabel(\"Log 10 Transform of Learning Rate\")\n",
        "        loss_coord = np.interp(np.log10(lr_to_use), np.log10(lrs), losses)\n",
        "        plt.plot(np.log10(lr_to_use), loss_coord, markersize=10,marker='o',color='red')\n",
        "        plt.show()\n",
        "        \n",
        "    return lr_to_use"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F2BOmZRYYKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_lr(model):\n",
        "    model.lr_find()\n",
        "    losses = np.array(model.sched.losses)\n",
        "    lrs = model.sched.lrs\n",
        "    losses_skipped = 5\n",
        "    trailing_losses_skipped = 5\n",
        "    losses = losses[losses_skipped:-trailing_losses_skipped]\n",
        "    lrs = lrs[losses_skipped:-trailing_losses_skipped]\n",
        "\n",
        "    n = len(losses)\n",
        "\n",
        "    max_start = 0\n",
        "    max_end = 0\n",
        "    \n",
        "    # finding the longest valley.\n",
        "    lds = [1] * n\n",
        "\n",
        "    for i in range(1, n):\n",
        "        for j in range(0, i):\n",
        "            if losses[i] < losses[j] and lds[i] < lds[j] + 1:\n",
        "                lds[i] = lds[j] + 1\n",
        "            if lds[max_end] < lds[i]:\n",
        "                max_end = i\n",
        "                max_start = max_end - lds[max_end]\n",
        "\n",
        "    sections = (max_end - max_start) / 3\n",
        "    final_index = max_start + int(sections) + int(sections/2) # pick something midway, or 2/3rd of the way to be more aggressive\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    ax.plot(\n",
        "        lrs,\n",
        "        losses\n",
        "    )\n",
        "    ax.set_ylabel(\"Loss\")\n",
        "    ax.set_xlabel(\"Learning Rate\")\n",
        "    ax.set_xscale('log')\n",
        "    ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n",
        "    ax.plot(\n",
        "        lrs[final_index],\n",
        "        losses[final_index],\n",
        "        markersize=10,\n",
        "        marker='o',\n",
        "        color='red'\n",
        "    )\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    return lrs[final_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECEDWRyItBpP",
        "colab_type": "text"
      },
      "source": [
        "# ZTM05 Architecture Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFKueqMrtHMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ZTM05:\n",
        "    def __process_params__(self):\n",
        "        self.train_dirs            = [Path(f\"{self.dataset_path}/{x.strip()}\") for x in self.train_dirs.split(\",\")]\n",
        "        self.deploy_dirs           = [Path(f\"{self.dataset_path}/{x.strip()}\") for x in self.deploy_dirs.split(\",\")]\n",
        "        self.downsampling_factors  = [int(x.strip())   for x in self.downsampling_factors.split(\",\")]\n",
        "        self.learning_rates        = [float(x.strip()) for x in self.learning_rates.split(\",\") if x.isdigit()]\n",
        "        self.cycles                = [int(x.strip())   for x in self.cycles.split(\",\")]\n",
        "        self.cycle_lengths         = [int(x.strip())   for x in self.cycle_lengths.split(\",\")]\n",
        "        self.batch_sizes           = [int(x.strip())   for x in self.batch_sizes.split(\",\")]\n",
        "        self.classes               = self.classes.split(\",\")\n",
        "    def __download__(self):\n",
        "        predictions_filename = f\"{self.result_filename}_predictions.csv\"\n",
        "        probability_filename = f\"{self.result_filename}_probability.csv\"\n",
        "        !rm -rf $self.dataset_path $self.output_path $predictions_filename $probability_filename\n",
        "        self.dataset_path = Path(self.dataset_path)\n",
        "        self.output_path  = Path(self.output_path)\n",
        "        !mkdir -p $self.dataset_path\n",
        "        downloader = Downloader()\n",
        "        downloader(dataset_file_name = self.dataset_file_name, \n",
        "                   dataset_file_id   = self.dataset_file_id)\n",
        "        !unzip -qq $self.dataset_file_name -d $self.dataset_path\n",
        "        !rm -rf $self.dataset_file_name\n",
        "    def __prepare_dataset__(self):\n",
        "        self.class2idx  = {x:i for i,x in enumerate(self.classes)}\n",
        "        self.ds_samples = load_all_dataset_samples(self.train_dirs, self.sample_rate, self.min_duration)\n",
        "        self.expected_length = get_expected_length(self.ds_samples)\n",
        "        self.ds_samples = process_dataset_samples(self.class2idx, self.ds_samples, self.expected_length, self.downsampling_factors)\n",
        "        (self.ds_samples_train, \n",
        "         self.ds_samples_test) = train_test_split(self.ds_samples, test_size=0.20)\n",
        "        self.x_train           = np.stack([s.samples_downsampled for s in self.ds_samples_train])\n",
        "        self.x_test            = np.stack([s.samples_downsampled for s in self.ds_samples_test])\n",
        "        self.y_train           = [s.y for s in self.ds_samples_train]\n",
        "        self.y_test            = [s.y for s in self.ds_samples_test]\n",
        "        self.trn_ds     = WavDataset(self.x_train, self.y_train, rotate_samples=True,  multi=50)\n",
        "        self.val_ds     = WavDataset(self.x_test,  self.y_test,  rotate_samples=False, multi=1)\n",
        "        self.trn_dl     = DataLoader(self.trn_ds, batch_size=self.batch_sizes[0], num_workers=1)\n",
        "        self.val_dl     = DataLoader(self.val_ds, batch_size=self.batch_sizes[0], num_workers=1)\n",
        "        self.custom_model_data = ModelData(self.output_path, self.trn_dl, self.val_dl)\n",
        "    def __build_custom_learner__(self):\n",
        "        self.custom_model      = HeartbeatSoundsConvNet(n_classes=len(self.classes))\n",
        "        if self.use_cuda:\n",
        "          self.custom_model = self.custom_model.cuda()\n",
        "          count_parameters(self.custom_model)\n",
        "        self.custom_single_model   = SingleModel(self.custom_model)\n",
        "        self.custom_learner        = Learner(self.custom_model_data, \n",
        "                                             self.custom_single_model, \n",
        "                                             crit=self.loss_function)\n",
        "        self.custom_learner.unfreeze()\n",
        "    def find_lrf(self):\n",
        "        self.custom_learner.lr_find()\n",
        "        return self.custom_learner.sched.lrs[np.argmin(self.custom_learner.sched.losses)]\n",
        "    def fit(self):\n",
        "        print(f\"{bcolors.FAIL}selecting first learning rate{bcolors.ENDC}\")\n",
        "        if len(self.learning_rates) < 1:\n",
        "            lr = find_appropriate_lr(self.custom_learner)\n",
        "        else:\n",
        "            lr = self.learning_rates[0]\n",
        "        print(f\"{bcolors.FAIL}\\t lr = {lr}{bcolors.ENDC}\")\n",
        "        vals, ep_vals = self.custom_learner.fit(lr, \n",
        "                                                self.cycles[0], \n",
        "                                                cycle_len=self.cycle_lengths[0], \n",
        "                                                get_ep_vals=True)\n",
        "        print(f\"{bcolors.FAIL}selecting second learning rate{bcolors.ENDC}\")\n",
        "        if len(self.learning_rates) < 2:\n",
        "            lr = find_lr(self.custom_learner)\n",
        "        else:\n",
        "            lr = self.learning_rates[1]\n",
        "        print(f\"{bcolors.FAIL}\\t lr = {lr}{bcolors.ENDC}\")\n",
        "        vals, ep_vals = self.custom_learner.fit(lr, \n",
        "                                                self.cycles[1], \n",
        "                                                cycle_len=self.cycle_lengths[1], \n",
        "                                                get_ep_vals=True)\n",
        "    def evaluate(self):\n",
        "        custom_learner_y_hat = predict_all(self.custom_model, \n",
        "                                       self.x_test, \n",
        "                                       n_classes=len(self.classes), \n",
        "                                       batch_size=self.batch_sizes[1], \n",
        "                                       use_cuda=self.use_cuda)\n",
        "        custom_learner_y_pred = np.argmax(custom_learner_y_hat, axis=1)\n",
        "        custom_learner_num_samples = len(self.x_test)\n",
        "        for i in range(len(self.classes)):\n",
        "            plt.figure(figsize=(15,5))\n",
        "            plt.title(self.classes[i])\n",
        "            plt.plot(custom_learner_y_hat[:,i], c='r')\n",
        "            plt.plot([y==i for y in self.y_test], c='b')\n",
        "            plt.xticks(range(custom_learner_num_samples), \n",
        "                       range(custom_learner_num_samples))\n",
        "            plt.show()\n",
        "        print(f\"{bcolors.OKGREEN}f1_score: {f1_score(self.y_test, custom_learner_y_pred, average='micro')}{bcolors.ENDC}\")\n",
        "        print(f\"{bcolors.OKGREEN}accuracy_score: {accuracy_score(self.y_test, custom_learner_y_pred)}{bcolors.ENDC}\")\n",
        "        cm = confusion_matrix(self.y_test, custom_learner_y_pred)\n",
        "        plot_confusion_matrix(cm, self.classes)\n",
        "        plt.show()\n",
        "    def deploy(self):\n",
        "        for samples_path in self.deploy_dirs:\n",
        "            filenames = sorted(list(samples_path.iterdir())); filenames[:3]\n",
        "            for fn_path in tqdm(filenames, desc=f\"{bcolors.OKGREEN}Deploying Model on Unclassified Samples{bcolors.ENDC} {bcolors.OKBLUE}{samples_path}{bcolors.ENDC}\"):\n",
        "                ds_sample = dataset_sample_from_file(fn_path, self.sample_rate)\n",
        "                ds_sample = process_dataset_sample(self.class2idx, \n",
        "                                                   ds_sample, \n",
        "                                                   self.expected_length, \n",
        "                                                   self.downsampling_factors)\n",
        "                yt, y_pred, a_class = predict_one(self.custom_model, \n",
        "                                                  ds_sample.samples_downsampled, \n",
        "                                                  self.use_cuda, \n",
        "                                                  n_classes=len(self.classes), \n",
        "                                                  classes=self.classes)\n",
        "                self.predictions_dict['ID'].append(fn_path.name)\n",
        "                self.predictions_dict['Prediction'].append(y_pred)\n",
        "                self.probability_dict['ID'].append(fn_path.name)\n",
        "                self.probability_dict['Prediction'].append(round(yt[y_pred], 3))\n",
        "        self.predictions_df = pd.DataFrame(self.predictions_dict)\n",
        "        self.probability_df = pd.DataFrame(self.probability_dict)\n",
        "        self.predictions_df.to_csv(f\"{self.result_filename}_predictions.csv\", sep=';', index=False)\n",
        "        self.probability_df.to_csv(f\"{self.result_filename}_probability.csv\", sep=';', index=False)\n",
        "    def __init__(self, \n",
        "                 sample_rate, \n",
        "                 downsampling_factors, \n",
        "                 min_duration, \n",
        "                 classes, \n",
        "                 train_dirs,\n",
        "                 deploy_dirs,\n",
        "                 dataset_path,\n",
        "                 dataset_file_name,\n",
        "                 dataset_file_id,\n",
        "                 use_cuda,\n",
        "                 output_path,\n",
        "                 batch_sizes,\n",
        "                 learning_rates,\n",
        "                 cycles,\n",
        "                 cycle_lengths,\n",
        "                 result_filename,\n",
        "                 loss_function):\n",
        "        self.sample_rate          = sample_rate\n",
        "        self.downsampling_factors = downsampling_factors\n",
        "        self.min_duration         = min_duration\n",
        "        self.classes              = classes\n",
        "        self.train_dirs           = train_dirs\n",
        "        self.deploy_dirs          = deploy_dirs\n",
        "        self.dataset_path         = dataset_path\n",
        "        self.dataset_file_name    = dataset_file_name\n",
        "        self.dataset_file_id      = dataset_file_id\n",
        "        self.use_cuda             = use_cuda\n",
        "        self.output_path          = output_path\n",
        "        self.batch_sizes          = batch_sizes\n",
        "        self.learning_rates       = learning_rates\n",
        "        self.cycles               = cycles\n",
        "        self.cycle_lengths        = cycle_lengths\n",
        "        self.result_filename      = result_filename\n",
        "        self.loss_function        = loss_function\n",
        "        self.predictions_dict = {'ID':[], 'Prediction':[]}\n",
        "        self.probability_dict = {'ID':[], 'Prediction':[]}\n",
        "        self.__download__()\n",
        "        self.__process_params__()\n",
        "        self.__prepare_dataset__()\n",
        "        self.__build_custom_learner__()\n",
        "        self.fit()\n",
        "        self.evaluate()\n",
        "        self.deploy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ftPfHOTCcF2",
        "colab_type": "text"
      },
      "source": [
        "# User Input: Data (New Dataset).\n",
        "- Training on : Full_wave_enhanced_audio.\n",
        "- Testing on  : Full_wave_enhanced_audio & Normalised_audio-chunks.\n",
        "\n",
        "### How to Select Training/Testing Folders\n",
        "- to select training folder, change the parameter called **train_dirs_param**:\n",
        "  - `train/Full_wave_enhanced_audio` will select one folder called `Full_wave_enhanced_audio` from the training folder, however `train/Full_wave_enhanced_audio, train/Normalised_audio-chunks` will select both `Full_wave_enhanced_audio` folder and `Normalised_audio-chunks` from the training folder.\n",
        "- to select testing folder, change the parameter called **train_dirs_param**:\n",
        "  - `test/Full_wave_enhanced_audio` will select one folder called `Full_wave_enhanced_audio` from the testing folder, however `test/Full_wave_enhanced_audio, test/Normalised_audio-chunks` will select both `Full_wave_enhanced_audio` folder and `Normalised_audio-chunks` from the testing folder.\n",
        "\n",
        "### How To Specify Other Parameters\n",
        "all parameters are separated by commas when they represent a collection.\n",
        "for example `downsampling_factors_param` represents a collection of three downsampling factors:\n",
        " - 8\n",
        " - 8\n",
        " - 4\n",
        "\n",
        "### Parameters which can be specified:\n",
        "- `dataset_file_name_param`: what the file name of the dataset **zip** archive is.\n",
        "- `dataset_file_id_param`: the google drive id of the dataset archive.\n",
        "- `dataset_path_param`: the path you wish the model to unzip the dataset archive to.\n",
        "- `use_cuda_param`: whether or not to use GPU.\n",
        "- `classes_param`: what classes you have inside the dataset (e.g. cc & cd), **NOTE** if you use multiple training/testing folders, they should have the same classes.\n",
        "- `train_dirs_param`: where you wish the model to split and preprocess the training data.\n",
        "- `deploy_dirs_param`: where you wish the model to split and preprocess the testing data.\n",
        "- `learning_rates_param`: the desired learning rates of the model while training.\n",
        "  - the training process is repeated twice, therefore we need two learning rates.\n",
        "  - if only one learning rate is provided the other learning rate will be generated inside the model using an lr_finder function.\n",
        "  - if no learning rates are provided then both learning rates will be generated inside the model using an lr_finder function.\n",
        "- `cycles_param`: the number of training cycles (epochs).\n",
        "  - the training process is repeated twice, therefore we need two cycle params.\n",
        "- `cycle_lengths_param`: the number of training iterations per cycle (iterations).\n",
        "  - the training process is repeated twice, therefore we need two cycle length params.\n",
        "- `result_filename_param`: the name of the result csv files.\n",
        "- `loss_function_param`: \n",
        "  - nll_loss: Negative Log Likelyhood.\n",
        "  - cross_entropy.\n",
        "- `batch_sizes`: be careful while choosing this one, not all batch sizes could accomodate all data, \"32,2\" seems to be good for the provided datasets.\n",
        "  - the first batch size (32): training batch size.\n",
        "  - the second batch size (2): testing/deployment batch size.\n",
        "\n",
        "**The rest of the parameters seem to be locked by the original developer, they are hardcoded into the core neural network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_SgvCRCjC0_",
        "colab_type": "text"
      },
      "source": [
        "# User Input: Data (New Dataset).\n",
        "- Training on : Full_wave_enhanced_audio & Normalised_audio-chunks.\n",
        "- Testing on  : Full_wave_enhanced_audio & Normalised_audio-chunks.\n",
        "\n",
        "\n",
        "### How to Select Training/Testing Folders\n",
        "- to select training folder, change the parameter called **train_dirs_param**:\n",
        "  - `train/Full_wave_enhanced_audio` will select one folder called `Full_wave_enhanced_audio` from the training folder, however `train/Full_wave_enhanced_audio, train/Normalised_audio-chunks` will select both `Full_wave_enhanced_audio` folder and `Normalised_audio-chunks` from the training folder.\n",
        "- to select testing folder, change the parameter called **test_dirs_param**:\n",
        "  - `test/Full_wave_enhanced_audio` will select one folder called `Full_wave_enhanced_audio` from the testing folder, however `test/Full_wave_enhanced_audio, test/Normalised_audio-chunks` will select both `Full_wave_enhanced_audio` folder and `Normalised_audio-chunks` from the testing folder.\n",
        "\n",
        "### How To Specify Other Parameters\n",
        "all parameters are separated by commas when they represent a collection.\n",
        "for example `downsampling_factors_param` represents a collection of three downsampling factors:\n",
        " - 8\n",
        " - 8\n",
        " - 4\n",
        "\n",
        "### Parameters which can be specified:\n",
        "- `dataset_file_name_param`: what the file name of the dataset **zip** archive is.\n",
        "- `dataset_file_id_param`: the google drive id of the dataset archive.\n",
        "- `dataset_path_param`: the path you wish the model to unzip the dataset archive to.\n",
        "- `use_cuda_param`: whether or not to use GPU.\n",
        "- `classes_param`: what classes you have inside the dataset (e.g. cc & cd), **NOTE** if you use multiple training/testing folders, they should have the same classes.\n",
        "- `train_dirs_param`: where you wish the model to split and preprocess the training data.\n",
        "- `deploy_dirs_param`: where you wish the model to split and preprocess the testing data.\n",
        "- `learning_rates_param`: the desired learning rates of the model while training.\n",
        "  - the training process is repeated twice, therefore we need two learning rates.\n",
        "  - if only one learning rate is provided the other learning rate will be generated inside the model using an lr_finder function.\n",
        "  - if no learning rates are provided then both learning rates will be generated inside the model using an lr_finder function.\n",
        "- `cycles_param`: the number of training cycles (epochs).\n",
        "  - the training process is repeated twice, therefore we need two cycle params.\n",
        "- `cycle_lengths_param`: the number of training iterations per cycle (iterations).\n",
        "  - the training process is repeated twice, therefore we need two cycle length params.\n",
        "- `result_filename_param`: the name of the result csv files.\n",
        "- `loss_function_param`: \n",
        "  - nll_loss: Negative Log Likelyhood.\n",
        "  - cross_entropy.\n",
        "- `batch_sizes`: be careful while choosing this one, not all batch sizes could accomodate all data, \"32,2\" seems to be good for the provided datasets.\n",
        "  - the first batch size (32): training batch size.\n",
        "  - the second batch size (2): testing/deployment batch size.\n",
        "\n",
        "**The rest of the parameters seem to be locked by the original developer, they are hardcoded into the core neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWABO5CVCccv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title User Input\n",
        "dataset_file_name_param    = \"ADReSS-IS2020-TrainAndTestData.zip\" #@param {type:\"string\"}\n",
        "dataset_file_id_param      = \"13Y8T0-Y1GrKdRLjJNCozBUUnAy4VXuLf\" #@param {type:\"string\"}\n",
        "dataset_path_param         = \"/\" #@param {type:\"string\"}\n",
        "use_cuda_param             = True    #@param {type:\"boolean\"}\n",
        "sample_rate_param          = 44100   #@param {type:\"integer\"}\n",
        "downsampling_factors_param = \"4,4,2\" #@param {type:\"string\"}\n",
        "min_duration_param         = None    #@param {type:\"raw\"}\n",
        "classes_param              = \"cc,cd\" #@param {type:\"string\"}\n",
        "train_dirs_param           = \"/content/ADReSS-IS2020-data/train/Full_wave_enhanced_audio\" #@param {type:\"string\"}\n",
        "deploy_dirs_param          = '/content/ADReSS-IS2020-data/test/Full_wave_enhanced_audio'  #@param {type:\"string\"}\n",
        "output_path_param          = '/content/data_processed'  #@param {type:\"string\"}\n",
        "batch_sizes_param           = \"32,2\" #@param {type:\"string\"}\n",
        "learning_rates_param       = \"0.2\" #@param {type:\"string\"}\n",
        "cycles_param               = \"4,4\" #@param {type:\"string\"}\n",
        "cycle_lengths_param        = \"8,8\" #@param {type:\"string\"}\n",
        "result_filename_param      = \"data_results\" #@param {type:\"string\"}\n",
        "loss_function_param = F.cross_entropy #@param [\"F.cross_entropy\", \"F.nll_loss\"] {type:\"raw\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztXy3qqZyu_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ZTM05(sample_rate_param, \n",
        "      downsampling_factors_param, \n",
        "      min_duration_param, \n",
        "      classes_param, \n",
        "      train_dirs_param,\n",
        "      deploy_dirs_param,\n",
        "      dataset_path_param,\n",
        "      dataset_file_name_param,\n",
        "      dataset_file_id_param,\n",
        "      use_cuda_param,\n",
        "      output_path_param,\n",
        "      batch_sizes_param,\n",
        "      learning_rates_param,\n",
        "      cycles_param,\n",
        "      cycle_lengths_param,\n",
        "      result_filename_param,\n",
        "      loss_function_param)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}